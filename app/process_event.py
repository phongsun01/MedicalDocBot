import asyncio
import json
import logging
import os
import re
import shutil
import sys
from pathlib import Path
from typing import Tuple, Any

import yaml
from dotenv import load_dotenv
from telegram import Bot
from telegram.constants import ParseMode
from telegram.helpers import escape_markdown

from app.classifier import MedicalClassifier
from app.index_store import IndexStore
from app.wiki_generator import WikiGenerator
from app.slug import build_device_slug
from app.taxonomy import Taxonomy
from app.utils import compute_sha256, clean_name

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Helper functions moved or removed (Dependency Injection used instead)

DOC_TYPE_MAP = {
    "ky_thuat": "K·ªπ thu·∫≠t",
    "cau_hinh": "C·∫•u h√¨nh",
    "bao_gia": "B√°o gi√°",
    "trung_thau": "Tr√∫ng th·∫ßu",
    "hop_dong": "H·ª£p ƒë·ªìng",
    "so_sanh": "So s√°nh",
    "thong_tin": "Th√¥ng tin",
    "lien_ket": "Li√™n k·∫øt",
    "khac": "Kh√°c"
}

# clean_name moved to app.utils

async def process_new_file(
    file_path: str,
    config: dict,
    classifier: MedicalClassifier,
    store: IndexStore,
    wiki: WikiGenerator,
    taxonomy: Taxonomy
):
    """
    Orchestrates the processing of a new document.
    """
    logger.info(f"--- B·∫Øt ƒë·∫ßu x·ª≠ l√Ω: {Path(file_path).name} ---")
    
    # 0. Ki·ªÉm tra n·∫øu file ƒë√£ c√≥ trong DB ·ªü ƒë∆∞·ªùng d·∫´n hi·ªán t·∫°i th√¨ b·ªè qua (ch·ªëng loop c·ªßa watcher)
    existing = await store.get_file(file_path)
    if existing:
        logger.info(f"File ƒë√£ t·ªìn t·∫°i trong DB, b·ªè qua: {file_path}")
        return
        
    # 1. Ph√¢n lo·∫°i b·∫±ng AI
    try:
        classification = await classifier.classify_file(file_path)
        logger.info(f"K·∫øt qu·∫£ ph√¢n lo·∫°i: {json.dumps(classification, ensure_ascii=False)}")
        
        doc_type = classification.get("doc_type", "khac")
        vendor = classification.get("vendor", "Unknown")
        model = classification.get("model", "Unknown")
        summary = classification.get("summary", "")
        
    except Exception as e:
        logger.error(f"D·ª´ng ti·∫øn tr√¨nh do l·ªói ph√¢n lo·∫°i AI: {e}")
        
        # B√°o l·ªói l√™n Telegram (MarkdownV2)
        token = os.getenv("TELEGRAM_BOT_TOKEN")
        group_chat_id = config["services"]["telegram"].get("group_chat_id")
        if token and group_chat_id:
            try:
                bot = Bot(token=token)
                safe_filename = escape_markdown(Path(file_path).name, version=2)
                safe_error = escape_markdown(str(e), version=2)
                error_report = f"‚ùå *L·ªói ph√¢n lo·∫°i t√†i li·ªáu\\!*\n\n" \
                               f"*File:* `{safe_filename}`\n" \
                               f"*L·ªói:* {safe_error}\n\n" \
                               f"Vui l√≤ng ki·ªÉm tra l·∫°i quota ho·∫∑c th·ª≠ l·∫°i sau\\."
                await bot.send_message(chat_id=group_chat_id, text=error_report, parse_mode=ParseMode.MARKDOWN_V2)
            except Exception as tg_err:
                logger.error(f"L·ªói g·ª≠i Telegram b√°o l·ªói: {tg_err}")
                
        return
        
    # Mapping doc_type sang ti·∫øng Vi·ªát
    doc_type_vi = DOC_TYPE_MAP.get(doc_type, doc_type)
    
    # 2. T·∫°o slugs
    device_slug = build_device_slug(vendor, model)
    full_category_slug = classification.get("category_slug", "")
    
    if "/" in full_category_slug:
        parts = full_category_slug.split("/")
        category_slug = clean_name(parts[0])
        group_slug = clean_name(parts[1])
    else:
        category_slug = clean_name(full_category_slug) if full_category_slug else "chua_phan_loai"
        group_slug = "khac"

    # --- Auto-correct AI Hallucinations ---
    CATEGORY_MAP = {
        "ngoai_khoa": "thiet_bi_phong_mo",
        "phau_thuat": "thiet_bi_phong_mo",
        "phong_mo": "thiet_bi_phong_mo",
        "trang_thiet_bi_phong_mo": "thiet_bi_phong_mo",
        "thiet-bi-phong-mo": "thiet_bi_phong_mo",
        "thiet_bi_hoi_suc": "hoi_suc_cap_cuu",
        "thiet_bi_hoi_suc_gay_me": "gay_me_may_tho",
        "Unknown": "chua_phan_loai",
        "khac": "chua_phan_loai"
    }

    GROUP_MAP = {
        "Unknown": "khac",
        "may_tho": "may_tho_hoi_suc",
        "phong_mo": "khac",
        "thiet_bi_phong_mo": "khac",
        "ban-mo": "ban_mo",
        "monitor_benh_nhan": "monitor",
        "may_theo_doi_benh_nhan": "monitor",
        "bon_rua_tay_phau_thuat": "bon_rua_tay"
    }

    category_slug = CATEGORY_MAP.get(category_slug, category_slug)
    group_slug = GROUP_MAP.get(group_slug, group_slug)
    
    # --- Strict Taxonomy Validation ---
    if not taxonomy.get_category(category_slug):
        logger.warning(f"AI sinh category_slug ·∫£o '{category_slug}', fallback v·ªÅ 'chua_phan_loai'.")
        category_slug = "chua_phan_loai"
        group_slug = "khac"
    elif not taxonomy.get_group(category_slug, group_slug):
        logger.warning(f"AI sinh group_slug ·∫£o '{group_slug}' (thu·ªôc {category_slug}), fallback v·ªÅ 'khac'.")
        group_slug = "khac"
    
    # 3. Di chuy·ªÉn file v√†o th∆∞ m·ª•c ph√¢n lo·∫°i
    root = Path(os.path.expandvars(os.path.expanduser(config["paths"]["medical_devices_root"])))
    target_relative = Path(category_slug) / group_slug / device_slug
    target_dir = root / target_relative
    target_dir.mkdir(parents=True, exist_ok=True)
    
    new_path = target_dir / Path(file_path).name
    
    # Ch·ªâ di chuy·ªÉn n·∫øu file ch∆∞a ·ªü ƒë√∫ng ch·ªó
    if Path(file_path).resolve() != new_path.resolve():
        try:
            # X√≥a entry c≈© trong DB tr∆∞·ªõc n·∫øu t·ªìn t·∫°i (ƒë·ªÅ ph√≤ng move l·ªói ho·∫∑c file ghi ƒë√®)
            await store.delete_file(str(file_path)) 
            shutil.move(file_path, new_path)
            logger.info(f"ƒê√£ di chuy·ªÉn file ƒë·∫øn: {new_path}")
            file_path = str(new_path)
        except Exception as e:
            logger.error(f"L·ªói khi di chuy·ªÉn file: {e}")
            # N·∫øu move fail, ta v·∫´n ti·∫øp t·ª•c v·ªõi original path? Kh√¥ng, t·ªët nh·∫•t l√† d·ª´ng.
            return
            
    # 4. L∆∞u v√†o Database (Strict Integrity)
    try:
        sha256 = compute_sha256(file_path)
    except Exception as e:
        logger.error(f"L·ªói nghi√™m tr·ªçng: Kh√¥ng th·ªÉ t√≠nh sha256 cho {file_path}. H·ªßy x·ª≠ l√Ω. {e}")
        raise # Strict integrity
        
    try:
        size_bytes = os.path.getsize(file_path)
    except OSError:
        size_bytes = 0

    await store.upsert_file(
        path=file_path,
        sha256=sha256,
        doc_type=doc_type,
        device_slug=device_slug,
        category_slug=category_slug,
        group_slug=group_slug,
        vendor=vendor,
        model=model,
        summary=summary,
        size_bytes=size_bytes,
        confirmed=True
    )
    logger.info(f"ƒê√£ l∆∞u v√†o DB: {file_path}")
    
    # 5. C·∫≠p nh·∫≠t Wiki
    device_info = {
        "vendor": vendor,
        "model": model,
        "category_id": category_slug,
        "category_slug": f"{category_slug}/{group_slug}"
    }
    
    all_files = await store.search(device_slug=device_slug)
    wiki_path = wiki.update_device_wiki(device_slug, device_info, all_files, taxonomy=taxonomy)
    logger.info(f"Wiki ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t: {wiki_path}")
    
    # 6. G·ª≠i b√°o c√°o Telegram (MarkdownV2)
    safe_vendor = escape_markdown(vendor, version=2)
    safe_model = escape_markdown(model, version=2)
    safe_doc_type = escape_markdown(doc_type_vi, version=2)
    safe_summary = escape_markdown(summary, version=2)
    safe_filename = escape_markdown(Path(file_path).name, version=2)
    safe_location = escape_markdown(str(target_relative), version=2)
    
    report = f"üìÑ *Ph√°t hi·ªán t√†i li·ªáu m·ªõi\\!*\n\n" \
             f"*File:* `{safe_filename}`\n" \
             f"*H√£ng:* {safe_vendor}\n" \
             f"*Model:* {safe_model}\n" \
             f"*Lo·∫°i:* {safe_doc_type}\n" \
             f"*T√≥m t·∫Øt:* {safe_summary}\n\n" \
             f"üìÅ *ƒê√£ l∆∞u v√†o:* `{safe_location}`\n\n" \
             f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t Wiki & Database\\."
    
    token = os.getenv("TELEGRAM_BOT_TOKEN")
    group_chat_id = config["services"]["telegram"].get("group_chat_id")
    
    if token and group_chat_id:
        try:
            bot = Bot(token=token)
            await bot.send_message(chat_id=group_chat_id, text=report, parse_mode=ParseMode.MARKDOWN_V2)
            logger.info(f"ƒê√£ g·ª≠i b√°o c√°o Telegram t·ªõi: {group_chat_id}")
        except Exception as e:
            logger.error(f"L·ªói g·ª≠i Telegram: {e}")
    
    logger.info("--- X·ª≠ l√Ω ho√†n t·∫•t ---")

async def main_cli():
    if len(sys.argv) < 2:
        print("Usage: python process_event.py <file_path>")
        return
        
    config_path = "config.yaml"
    with open(config_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
        
    classifier = MedicalClassifier(config_path)
    store = IndexStore(config["paths"]["db_file"])
    await store.init()
    wiki = WikiGenerator(config_path)
    taxonomy = Taxonomy(config["paths"]["taxonomy_file"])
    
    try:
        await process_new_file(sys.argv[1], config, classifier, store, wiki, taxonomy)
    finally:
        await store.close()

if __name__ == "__main__":
    asyncio.run(main_cli())
