import asyncio
import html
import json
import logging
import os
import shutil
import sys
from pathlib import Path

import yaml
from dotenv import load_dotenv
from telegram import Bot
from telegram.constants import ParseMode
from telegram.helpers import escape_markdown

from app.classifier import MedicalClassifier
from app.index_store import IndexStore
from app.slug import build_device_slug
from app.taxonomy import Taxonomy
from app.utils import clean_name, compute_sha256
from app.wiki_generator import WikiGenerator

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Helper functions moved or removed (Dependency Injection used instead)

DOC_TYPE_MAP = {
    "ky_thuat": "K·ªπ thu·∫≠t",
    "cau_hinh": "C·∫•u h√¨nh",
    "bao_gia": "B√°o gi√°",
    "trung_thau": "Tr√∫ng th·∫ßu",
    "hop_dong": "H·ª£p ƒë·ªìng",
    "so_sanh": "So s√°nh",
    "thong_tin": "Th√¥ng tin",
    "lien_ket": "Li√™n k·∫øt",
    "khac": "Kh√°c",
}

# clean_name moved to app.utils



def detect_manual_placement(file_path: str, config: dict) -> dict | None:
    """
    Checks if a file is already placed in a valid taxonomy folder.
    Returns metadata if detected, else None.
    Structure: ROOT / category / group / device / doc_type_folder / filename
    """
    try:
        root_path = Path(os.path.expandvars(os.path.expanduser(config["paths"]["medical_devices_root"]))).resolve()
        file_path_obj = Path(file_path).resolve()
        
        if not str(file_path_obj).startswith(str(root_path)):
            return None
            
        rel_parts = file_path_obj.relative_to(root_path).parts
        
        # Expected: (category, group, device, sub_dir, filename) -> length 5
        if len(rel_parts) != 5:
            return None
            
        category_slug, group_slug, device_slug, sub_dir, filename = rel_parts
        
        # Map sub_dir back to doc_type
        doc_type = config.get("classifier", {}).get("subfolder_rules", {}).get(sub_dir)
        
        if not doc_type:
            return None
            
        # Try to parse vendor/model from device_slug
        parts = device_slug.split("_")
        vendor = parts[0].capitalize() if len(parts) > 0 else "Unknown"
        model = "_".join(parts[1:]).upper() if len(parts) > 1 else "Unknown"
        
        return {
            "doc_type": doc_type,
            "category_slug": f"{category_slug}/{group_slug}",
            "vendor": vendor,
            "model": model,
            "confidence": 1.0,
            "summary": f"ƒê·∫∑t th·ªß c√¥ng t·∫°i /{sub_dir}",
            "device_slug": device_slug  # Keep consistency
        }
    except Exception:
        return None


async def process_new_file(
    file_path: str,
    config: dict,
    classifier: MedicalClassifier,
    store: IndexStore,
    wiki: WikiGenerator,
    taxonomy: Taxonomy,
):
    """
    Orchestrates the processing of a new document.
    """
    logger.info(f"--- B·∫Øt ƒë·∫ßu x·ª≠ l√Ω: {Path(file_path).name} ---")

    # 0. Ki·ªÉm tra n·∫øu file ƒë√£ c√≥ trong DB ·ªü ƒë∆∞·ªùng d·∫´n hi·ªán t·∫°i th√¨ b·ªè qua (ch·ªëng loop c·ªßa watcher)
    existing = await store.get_file(file_path)
    if existing:
        logger.info(f"File ƒë√£ t·ªìn t·∫°i trong DB, b·ªè qua: {file_path}")
        return

    # 1. Ph√¢n lo·∫°i
    classification = None
    manual_info = detect_manual_placement(file_path, config)
    
    if manual_info:
        logger.info(f"Ph√°t hi·ªán file ƒë·∫∑t th·ªß c√¥ng: {manual_info.get('device_slug')}")
        classification = manual_info
    else:
        try:
            classification = await classifier.classify_file(file_path)
            logger.info(f"K·∫øt qu·∫£ ph√¢n lo·∫°i AI: {json.dumps(classification, ensure_ascii=False)}")
        except Exception as e:
            logger.error(f"D·ª´ng ti·∫øn tr√¨nh do l·ªói ph√¢n lo·∫°i AI: {e}")
            # ... handle error as before ...
            token = os.getenv("TELEGRAM_BOT_TOKEN")
            group_chat_id = config["services"]["telegram"].get("group_chat_id")
            if token and group_chat_id:
                try:
                    bot = Bot(token=token)
                    safe_filename = html.escape(Path(file_path).name)
                    safe_error = html.escape(str(e))
                    error_report = (
                        f"‚ùå <b>L·ªói ph√¢n lo·∫°i t√†i li·ªáu!</b>\n\n"
                        f"<b>File:</b> <code>{safe_filename}</code>\n"
                        f"<b>L·ªói:</b> {safe_error}\n\n"
                        f"Vui l√≤ng ki·ªÉm tra l·∫°i quota ho·∫∑c th·ª≠ l·∫°i sau."
                    )
                    await bot.send_message(
                        chat_id=group_chat_id, text=error_report, parse_mode=ParseMode.HTML
                    )
                except Exception as tg_err:
                    logger.error(f"L·ªói g·ª≠i Telegram b√°o l·ªói: {tg_err}")
            return

    # Extract classified data
    doc_type = classification.get("doc_type", "khac")
    vendor = classification.get("vendor", "Unknown")
    model = classification.get("model", "Unknown")
    summary = classification.get("summary", "")
    confidence = classification.get("confidence", None)

    # T·ª± ∆∞·ªõc t√≠nh confidence n·∫øu AI kh√¥ng tr·∫£ v·ªÅ
    if confidence is None:
        if vendor != "Unknown" and model != "Unknown" and doc_type != "khac":
            confidence = 0.8  # ƒê·ªß th√¥ng tin: vendor + model + doc_type
        elif doc_type != "khac" and classification.get("category_slug"):
            confidence = 0.75  # C√≥ doc_type v√† category l√† ƒë·ªß
        else:
            confidence = 0.5   # Th√¥ng tin m∆° h·ªì, ƒë·ªÉ user x√°c nh·∫≠n
        logger.info(f"AI kh√¥ng tr·∫£ v·ªÅ confidence, ∆∞·ªõc t√≠nh: {confidence}")

    # ƒê·∫£m b·∫£o confidence l√† s·ªë h·ª£p l·ªá
    try:
        confidence = float(confidence)
    except (TypeError, ValueError):
        confidence = 0.5

    # Mapping doc_type sang ti·∫øng Vi·ªát
    doc_type_vi = DOC_TYPE_MAP.get(doc_type, doc_type)

    # 2. T·∫°o slugs
    device_slug = build_device_slug(vendor, model)
    full_category_slug = classification.get("category_slug", "")

    if "/" in full_category_slug:
        parts = full_category_slug.split("/")
        category_slug = clean_name(parts[0])
        group_slug = clean_name(parts[1])
    else:
        category_slug = clean_name(full_category_slug) if full_category_slug else "chua_phan_loai"
        group_slug = "khac"

    # --- Auto-correct AI Hallucinations ---
    CATEGORY_MAP = {
        "ngoai_khoa": "thiet_bi_phong_mo",
        "phau_thuat": "thiet_bi_phong_mo",
        "phong_mo": "thiet_bi_phong_mo",
        "trang_thiet_bi_phong_mo": "thiet_bi_phong_mo",
        "thiet-bi-phong-mo": "thiet_bi_phong_mo",
        "thiet_bi_hoi_suc": "hoi_suc_cap_cuu",
        "thiet_bi_hoi_suc_gay_me": "gay_me_may_tho",
        "Unknown": "chua_phan_loai",
        "khac": "chua_phan_loai",
    }

    GROUP_MAP = {
        "Unknown": "khac",
        "may_tho": "may_tho_hoi_suc",
        "phong_mo": "khac",
        "thiet_bi_phong_mo": "khac",
        "ban-mo": "ban_mo",
        "monitor_benh_nhan": "monitor",
        "may_theo_doi_benh_nhan": "monitor",
        "bon_rua_tay_phau_thuat": "bon_rua_tay",
    }

    category_slug = CATEGORY_MAP.get(category_slug, category_slug)
    group_slug = GROUP_MAP.get(group_slug, group_slug)

    # --- Strict Taxonomy Validation ---
    if not taxonomy.get_category(category_slug):
        logger.warning(f"AI sinh category_slug ·∫£o '{category_slug}', fallback v·ªÅ 'chua_phan_loai'.")
        category_slug = "chua_phan_loai"
        group_slug = "khac"
    elif not taxonomy.get_group(category_slug, group_slug):
        logger.warning(
            f"AI sinh group_slug ·∫£o '{group_slug}' (thu·ªôc {category_slug}), fallback v·ªÅ 'khac'."
        )
        group_slug = "khac"

    # --- Always require manual confirmation as per SPECS (UC1) ---
    threshold = config.get("classifier", {}).get("confidence_threshold", 0.7)
    is_confident = confidence >= threshold

    # 3. T√≠nh to√°n v·ªã tr√≠ t∆∞∆°ng lai (nh∆∞ng CH∆ØA di chuy·ªÉn)
    root = Path(os.path.expandvars(os.path.expanduser(config["paths"]["medical_devices_root"])))
    target_relative = Path(category_slug) / group_slug / device_slug

    if not is_confident:
        logger.info(f"ƒê·ªô tin c·∫≠y th·∫•p ({confidence} < {threshold}).")

    logger.info(f"Ch·ªù ng∆∞·ªùi d√πng x√°c nh·∫≠n th·ªß c√¥ng cho file: {file_path}")

    # 4. L∆∞u v√†o Database (Strict Integrity)
    try:
        sha256 = compute_sha256(file_path)
    except Exception as e:
        logger.error(f"L·ªói nghi√™m tr·ªçng: Kh√¥ng th·ªÉ t√≠nh sha256 cho {file_path}. H·ªßy x·ª≠ l√Ω. {e}")
        raise  # Strict integrity

    try:
        size_bytes = os.path.getsize(file_path)
    except OSError:
        size_bytes = 0

    file_id = await store.upsert_file(
        path=file_path,
        sha256=sha256,
        doc_type=doc_type,
        device_slug=device_slug,
        category_slug=category_slug,
        group_slug=group_slug,
        vendor=vendor,
        model=model,
        summary=summary,
        size_bytes=size_bytes,
        confirmed=False,  # ALWAYS False until user clicks approve
    )
    logger.info(f"ƒê√£ l∆∞u v√†o DB (DRAFT): {file_path} (ID: {file_id})")

    # 5. C·∫≠p nh·∫≠t Wiki -> B·ªè qua, ch·ªâ l√†m khi user ·∫•n Confirm

    # 6. G·ª≠i b√°o c√°o Telegram (HTML)
    esc = html.escape  # T·∫ØtƒÉt
    safe_filename = esc(Path(file_path).name)
    safe_vendor = esc(vendor)
    safe_model = esc(model)
    safe_doc_type = esc(doc_type_vi)
    safe_summary = esc(summary)
    safe_location = esc(str(target_relative))
    safe_confidence = f"{confidence * 100:.0f}%"

    if is_confident:
        report = (
            f"üìÑ <b>Ph√°t hi·ªán t√†i li·ªáu m·ªõi!</b> (ƒê·ªô tin c·∫≠y cao)\n\n"
            f"<b>File:</b> <code>{safe_filename}</code>\n"
            f"<b>H√£ng:</b> {safe_vendor}\n"
            f"<b>Model:</b> {safe_model}\n"
            f"<b>Lo·∫°i:</b> {safe_doc_type} ({safe_confidence})\n"
            f"<b>T√≥m t·∫Øt:</b> <i>{safe_summary}</i>\n\n"
            f"üìÅ <b>ƒê·ªÅ xu·∫•t l∆∞u v√†o:</b> <code>{safe_location}</code>\n\n"
            f"Vui l√≤ng x√°c nh·∫≠n ƒë·ªÉ h·ªá th·ªëng l∆∞u v√† c·∫≠p nh·∫≠t Wiki."
        )
    else:
        report = (
            f"‚ö†Ô∏è <b>C·∫ßn x√°c nh·∫≠n ph√¢n lo·∫°i!</b> (AI kh√¥ng ch·∫Øc ch·∫Øn)\n\n"
            f"<b>File:</b> <code>{safe_filename}</code>\n"
            f"<b>H√£ng ƒë·ªÅ xu·∫•t:</b> {safe_vendor}\n"
            f"<b>Model ƒë·ªÅ xu·∫•t:</b> {safe_model}\n"
            f"<b>Lo·∫°i d·ª± ƒëo√°n:</b> {safe_doc_type} ({safe_confidence})\n"
            f"<b>T√≥m t·∫Øt:</b> <i>{safe_summary}</i>\n\n"
            f"üìÅ <b>ƒê·ªÅ xu·∫•t l∆∞u v√†o:</b> <code>{safe_location}</code>\n\n"
            f"Vui l√≤ng x√°c nh·∫≠n ƒë·ªÉ h·ªá th·ªëng l∆∞u v√† c·∫≠p nh·∫≠t Wiki."
        )

    from telegram import InlineKeyboardButton, InlineKeyboardMarkup

    keyboard = [
        [
            InlineKeyboardButton("‚úÖ Ph√™ duy·ªát", callback_data=f"approve_{file_id}"),
            InlineKeyboardButton("‚úèÔ∏è Ch·ªânh s·ª≠a", callback_data=f"edit_{file_id}"),
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    token = os.getenv("TELEGRAM_BOT_TOKEN")
    group_chat_id = config["services"]["telegram"].get("group_chat_id")

    if token and group_chat_id:
        try:
            bot = Bot(token=token)
            await bot.send_message(
                chat_id=group_chat_id,
                text=report,
                parse_mode=ParseMode.HTML,
                reply_markup=reply_markup,
            )
            logger.info(f"ƒê√£ g·ª≠i b√°o c√°o Telegram t·ªõi: {group_chat_id}")
        except Exception as e:
            logger.error(f"L·ªói g·ª≠i Telegram: {e}")

    logger.info("--- X·ª≠ l√Ω ho√†n t·∫•t ---")


async def main_cli():
    if len(sys.argv) < 2:
        print("Usage: python process_event.py <file_path>")
        return

    config_path = "config.yaml"
    with open(config_path, encoding="utf-8") as f:
        config = yaml.safe_load(f)

    classifier = MedicalClassifier(config_path)
    store = IndexStore(config["paths"]["db_file"])
    await store.init()
    wiki = WikiGenerator(config_path)
    taxonomy = Taxonomy(config["paths"]["taxonomy_file"])

    try:
        await process_new_file(sys.argv[1], config, classifier, store, wiki, taxonomy)
    finally:
        await store.close()


if __name__ == "__main__":
    asyncio.run(main_cli())
